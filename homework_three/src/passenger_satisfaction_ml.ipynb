{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYCK8Y-lTb3O"
   },
   "source": [
    "# Tarea 3\n",
    "\n",
    "Autor: Fabian Morera Gutierrez\n",
    "\n",
    "Profesor: Dr. Juan Manuel Esquivel Rodriguez\n",
    "\n",
    "Curso: Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXPbCqJLTb3Q"
   },
   "source": [
    "# Entrenamiento de un modelo de clasificación binaria.\n",
    "\n",
    "El presente programa tiene como finalidad la creación de un modelo de clasificaciónbinaria, de principio a fin, utilizando el framwork Apache Spark. Para tal fin, se utilizará una fuente de datos en formato CSV,la cual se describirá con mayor detalle más adelante. \n",
    "\n",
    "Para lograr el objetivo, se iniciará desde la lectura de los datos, limpieza de los mismos, análisis descriptivo, almacenamiento intermedio y entrenamiento de un modelo de regresión.\n",
    "\n",
    "Para esta tarea se utiliza un conjunto de datos relacionado con la predicción binaria de la satisfacción de los clientes de una aerolínera ficticia llamada Invistico, la cual se puede descargar desde https://www.kaggle.com/sjleshrac/airlines-customer-satisfaction."
   ]
  },
  {
   "source": [
    "# Dataset: Invistico Airlines\n",
    "\n",
    "Este dataset incluye información relacionada con la retroalimentación de clientes pasados, que volaron con dicha compañía, así como de información específica del vuelo en cuestión de cada entrevistado.\n",
    "\n",
    "El objetivo principal de este set de datos, es el de lograr predecir si un futuro cliente de la aerolínea se mostrará satisfecho con el servicio proveído, o no, dados los valores de los demás parámetros.\n",
    "\n",
    "Los parámetros originales del dataset son los siguientes:\n",
    "\n",
    "Nota: Los nombres se encuentran tal y como estan escritos en el archivo original. Igualmete, dado el contexto, los términos pasajero, cliente e usuario son equivalentes.\n",
    "\n",
    "- satisfaction: String. Estado de satisfacción del usuario, con las opciones \"satisfied\" y \"dissatisfied\". \n",
    "- Gender: String. Género del usuario.\n",
    "- Customer Type: String. Categoría del usuario, con las opciones binarias \"Loyal Customer\" y \"disloyal Customer\".\n",
    "- Age: Integer. Edad completa del usuario volando.\n",
    "- Type of Travel: String. Tipo de vuelo realizado, ya sea \"Business travel\" o \"Personal Travel\".\n",
    "- Class: String. Clase de asiento o tiquete del pasajaro. (Por ejemplo, \"Business\", \"Eco\", etc.).\n",
    "- Flight Distance: Integer. Distancia total del vuelo.\n",
    "- Seat comfort: Integer (0-5). Grado de confort del asiento.\n",
    "- Departure/Arrival time convenient: Integer (0-5). Grado de conveniencia de las horas de despegue y aterrizaje según el pasajero y sus necesidades.\n",
    "- Food and Drink: Integer (0-5). Nivel de agrado con la calidad y cantidad de alimentación y bebidas otorgadas al usuario.\n",
    "- Gate location: Integer (0-5). Nivel de satisfacción del pasajero con la ubicación de ls puerta de abordaje dentro del aeropuerto.\n",
    "- Inflight wifi service: Integer (0-5). Nivel de satisfacción del pasajero con la disponibilidad y/o calidad del servicio de wifi dentro del avión.\n",
    "- Inflight entertainment: Integer (0-5). Nivel de satisfacción del pasajero con las opciones y/o calidad del entretenimiento disponible a bordo del avión.\n",
    "- Online support: Integer (0-5). Nivel de satisfacción con el soporte al cliente via online.\n",
    "- Ease of Online bookin: Integer (0-5). Nivel de satisfacción del cliente con el sistema de reserva online para el vuelo en cuestión.\n",
    "- On-board service: Integer (0-5). Grado de satisfacción del pasajero con el servicio de abordaje.\n",
    "- Leg room service: Integer (0-5). Grado de satisfacción del cliente con el espacio disponible para las piernas a bordo del avión.\n",
    "- Baggage handling: Integer (0-5). Nivel de satisfacción del cliente con el manejo de sus maletas durante todo el proceso.\n",
    "- Checkin service: Integer (0-5). Grado de satiscacción del usuario con el servicio de \"Check-In\" proporsionado para el vuelo.\n",
    "- Cleanliness: Integer (0-5).Nivel de satisfacción del pasajero respecto a la limpieza del avión.\n",
    "- Online boarding: Integer (0-5). Grado de satisfacción del usuario respecto al servicio de abordaje online.\n",
    "- Departure Delay in Minutes: Integer. Cantidad de minutos de retraso del despegue, según la hora establecida originalmente.\n",
    "- Arrival Delay in Minutes: Integer. Cantidad de minutos de retraso del aterrizaje, según la hora establecida originalmente.\n",
    "\n",
    "## Variable a predecir: satisfaction. \n",
    "(Traducida eventualmente a una variable binaria \"isSatisfied\", la cual denota si el pasajero se encuentra satisfecho, o no, con el servicio otorgado).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dependencias\n",
    "Importamos dependencias requeridas a lo largo del programa aquí."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy y Matplotlib.\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Others.\n",
    "import findspark\n",
    "import tempfile\n",
    "import random\n",
    "\n",
    "# Pyspark main.\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Pyspark machine learning.\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.tuning import CrossValidatorModel, CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler, HashingTF, Tokenizer, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Seaborn.\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Dependencies loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BvlqRf1PTb3R"
   },
   "source": [
    "# Lectura y limpieza \n",
    "Una de las tareas más comunes al procesar datos es el ajuste y limpieza de los datos. En las celdas siguientes leeremos los datos del archivo Invistico_Airline.csv y realizaremos diferentes pasos para poder cargar los datos a una tabla en PostgreSQL que almacenará el conjunto de datos en su forma deseada para abordar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBbCLAzXTb3S",
    "outputId": "0bf8d265-bd7c-40ee-e9cd-c5c01cbf30b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- bathrooms: float (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: string (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- sqft_above: integer (nullable = true)\n",
      " |-- sqft_basement: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- sqft_living15: integer (nullable = true)\n",
      " |-- sqft_lot15: integer (nullable = true)\n",
      "\n",
      "+----------+---------------+----------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|        id|           date|     price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n",
      "+----------+---------------+----------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|7129300520|20141013T000000|    221900|       3|      1.0|       1180|    5650|     1|         0|   0|        3|    7|      1180|            0|    1955|           0|  98178|47.5112|-122.257|         1340|      5650|\n",
      "|6414100192|20141209T000000|    538000|       3|     2.25|       2570|    7242|     2|         0|   0|        3|    7|      2170|          400|    1951|        1991|  98125| 47.721|-122.319|         1690|      7639|\n",
      "|5631500400|20150225T000000|    180000|       2|      1.0|        770|   10000|     1|         0|   0|        3|    6|       770|            0|    1933|           0|  98028|47.7379|-122.233|         2720|      8062|\n",
      "|2487200875|20141209T000000|    604000|       4|      3.0|       1960|    5000|     1|         0|   0|        5|    7|      1050|          910|    1965|           0|  98136|47.5208|-122.393|         1360|      5000|\n",
      "|1954400510|20150218T000000|    510000|       3|      2.0|       1680|    8080|     1|         0|   0|        3|    8|      1680|            0|    1987|           0|  98074|47.6168|-122.045|         1800|      7503|\n",
      "|7237550310|20140512T000000|1.225e+006|       4|      4.5|       5420|  101930|     1|         0|   0|        3|   11|      3890|         1530|    2001|           0|  98053|47.6561|-122.005|         4760|    101930|\n",
      "|1321400060|20140627T000000|    257500|       3|     2.25|       1715|    6819|     2|         0|   0|        3|    7|      1715|            0|    1995|           0|  98003|47.3097|-122.327|         2238|      6819|\n",
      "|2008000270|20150115T000000|    291850|       3|      1.5|       1060|    9711|     1|         0|   0|        3|    7|      1060|            0|    1963|           0|  98198|47.4095|-122.315|         1650|      9711|\n",
      "|2414600126|20150415T000000|    229500|       3|      1.0|       1780|    7470|     1|         0|   0|        3|    7|      1050|          730|    1960|           0|  98146|47.5123|-122.337|         1780|      8113|\n",
      "|3793500160|20150312T000000|    323000|       3|      2.5|       1890|    6560|     2|         0|   0|        3|    7|      1890|            0|    2003|           0|  98038|47.3684|-122.031|         2390|      7570|\n",
      "|1736800520|20150403T000000|    662500|       3|      2.5|       3560|    9796|     1|         0|   0|        3|    8|      1860|         1700|    1965|           0|  98007|47.6007|-122.145|         2210|      8925|\n",
      "|9212900260|20140527T000000|    468000|       2|      1.0|       1160|    6000|     1|         0|   0|        4|    7|       860|          300|    1942|           0|  98115|  47.69|-122.292|         1330|      6000|\n",
      "|0114101516|20140528T000000|    310000|       3|      1.0|       1430|   19901|   1.5|         0|   0|        4|    7|      1430|            0|    1927|           0|  98028|47.7558|-122.229|         1780|     12697|\n",
      "|6054650070|20141007T000000|    400000|       3|     1.75|       1370|    9680|     1|         0|   0|        4|    7|      1370|            0|    1977|           0|  98074|47.6127|-122.045|         1370|     10208|\n",
      "|1175000570|20150312T000000|    530000|       5|      2.0|       1810|    4850|   1.5|         0|   0|        3|    7|      1810|            0|    1900|           0|  98107|  47.67|-122.394|         1360|      4850|\n",
      "|9297300055|20150124T000000|    650000|       4|      3.0|       2950|    5000|     2|         0|   3|        3|    9|      1980|          970|    1979|           0|  98126|47.5714|-122.375|         2140|      4000|\n",
      "|1875500060|20140731T000000|    395000|       3|      2.0|       1890|   14040|     2|         0|   0|        3|    7|      1890|            0|    1994|           0|  98019|47.7277|-121.962|         1890|     14018|\n",
      "|6865200140|20140529T000000|    485000|       4|      1.0|       1600|    4300|   1.5|         0|   0|        4|    7|      1600|            0|    1916|           0|  98103|47.6648|-122.343|         1610|      4300|\n",
      "|0016000397|20141205T000000|    189000|       2|      1.0|       1200|    9850|     1|         0|   0|        4|    7|      1200|            0|    1921|           0|  98002|47.3089| -122.21|         1060|      5095|\n",
      "|7983200060|20150424T000000|    230000|       3|      1.0|       1250|    9774|     1|         0|   0|        4|    7|      1250|            0|    1969|           0|  98003|47.3343|-122.306|         1280|      8850|\n",
      "+----------+---------------+----------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "findspark.init('/usr/lib/python3.7/site-packages/pyspark')\n",
    "\n",
    "# Cargar el conjunto de datos completo. Este paso no realiza ningún ajuste; simplemente lectura\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Basic JDBC pipeline\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"postgresql-42.2.14.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"postgresql-42.2.14.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Lectura y definición del schema para los datos iniciales.\n",
    "flights_df = spark \\\n",
    "    .read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", \"../resources/Invistico_Airline.csv\") \\\n",
    "    .option(\"header\", False) \\\n",
    "    .schema(StructType([\n",
    "        StructField(\"satisfaction\", StringType()),\n",
    "        StructField(\"gender\", StringType()),\n",
    "        StructField(\"customer_type\", StringType()),\n",
    "        StructField(\"age\", IntegerType()),\n",
    "        StructField(\"type_of_travel\", StringType()),\n",
    "        StructField(\"class\", StringType()),\n",
    "        StructField(\"flight_distance\", IntegerType()),\n",
    "        StructField(\"seat_comfort\", IntegerType()),\n",
    "        StructField(\"departure_arrival_time_convenient\", IntegerType()),\n",
    "        StructField(\"food_drink\", IntegerType()),\n",
    "        StructField(\"gate_location\", IntegerType()),\n",
    "        StructField(\"inflight_wifi_service\", IntegerType()),\n",
    "        StructField(\"inflight_entertainment\", IntegerType()),\n",
    "        StructField(\"online_support\", IntegerType()),\n",
    "        StructField(\"ease_of_online_booking\", IntegerType()),\n",
    "        StructField(\"onboard_service\", IntegerType()),\n",
    "        StructField(\"leg_room_service\", IntegerType()),\n",
    "        StructField(\"baggage_handling\", IntegerType()),\n",
    "        StructField(\"checkin_service\", IntegerType()),\n",
    "        StructField(\"cleanliness\", IntegerType()),\n",
    "        StructField(\"online_boarding\", IntegerType()),\n",
    "        StructField(\"departure_delay_minutes\", IntegerType()),\n",
    "        StructField(\"arrival_delay_minutes\", IntegerType())])) \\\n",
    "    .load()\n",
    "\n",
    "flights_df.printSchema()\n",
    "flights_df.show()"
   ]
  },
  {
   "source": [
    "## Ajuste de variables.\n",
    "Algunas variables tienen que ser reinterpretadas como valores numéricos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajusta tipo de columnas para que sean númericas.\n",
    "flights_df = flights_df.na.drop()\n",
    "\n",
    "correct_types_df = flights_df \\\n",
    "    .withColumn('satisfaction', F.upper(F.col('satisfaction'))) \\\n",
    "    .withColumn(\"satisfaction\", F.trim(F.col(\"satisfaction\"))) \\\n",
    "    .withColumn('customer_type', F.upper(F.col('customer_type'))) \\\n",
    "    .withColumn(\"customer_type\", F.trim(F.col(\"customer_type\"))) \\\n",
    "    .withColumn('gender', F.upper(F.col('gender'))) \\\n",
    "    .withColumn(\"gender\", F.trim(F.col(\"gender\"))) \\\n",
    "    .withColumn('type_of_travel', F.upper(F.col('type_of_travel'))) \\\n",
    "    .withColumn(\"type_of_travel\", F.trim(F.col(\"type_of_travel\"))) \\\n",
    "    .withColumn('class', F.upper(F.col('class'))) \\\n",
    "    .withColumn(\"class\", F.trim(F.col(\"class\"))) \\\n",
    "    .withColumn('isSatisfied',\n",
    "                F.when(F.col('satisfaction') == \"SATISFIED\", 1)\n",
    "                .when(F.col('satisfaction') == \"DISSATISFIED\", 0)) \\\n",
    "    .withColumn('isMale',\n",
    "                F.when(F.col(\"gender\") == \"MALE\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isFemale', \n",
    "                F.when(F.col(\"gender\") == \"FEMALE\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isLoyalCustomer', \n",
    "                F.when(F.col(\"customer_type\") == \"LOYAL CUSTOMER\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isDisloyalCustomer', \n",
    "                F.when(F.col(\"customer_type\") == \"DISLOYAL CUSTOMER\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isBusinessTravel', \n",
    "                F.when(F.col(\"type_of_travel\") == \"BUSINESS TRAVEL\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isPersonalTravel', \n",
    "                F.when(F.col(\"type_of_travel\") == \"PERSONAL TRAVEL\", 1)\n",
    "                .otherwise(0)) \\\n",
    "     .withColumn('isBusinessClass', \n",
    "                F.when(F.col(\"class\") == \"BUSINESS\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isEcoClass', \n",
    "                F.when(F.col(\"class\") == \"ECO\", 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn('isOtherClass', \n",
    "                F.when((F.col(\"class\") != \"ECO\") & (F.col(\"class\") != \"BUSINESS\"), 1)\n",
    "                .otherwise(0))\n",
    "\n",
    "# Eliminar las columnas que ya no se necesitan dado a los cambios anteriores.\n",
    "correct_types_df = correct_types_df \\\n",
    "    .drop(F.col(\"satisfaction\")) \\\n",
    "    .drop(F.col(\"gender\")) \\\n",
    "    .drop(F.col(\"customer_type\")) \\\n",
    "    .drop(F.col(\"type_of_travel\")) \\\n",
    "    .drop(F.col(\"class\")) \\\n",
    "\n",
    "# Print.\n",
    "print(\"Corrected Types:\\n\")\n",
    "correct_types_df.printSchema()\n",
    "correct_types_df.show()"
   ]
  },
  {
   "source": [
    "## Almacenar en Base de Datos.\n",
    "Se almacena el conjunto de datos limpios en la tabla \"flights\" dentro de un contenedor de postgres."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenar el conjunto de datos limpio en la base de datos, la cual debe correr en \n",
    "# un contenedor aparte al momento de ejecutarse.\n",
    "\n",
    "# Utilizamos el método de sobreescribir.\n",
    "OVERWRITE_MODE = 'overwrite'\n",
    "\n",
    "correct_types_df \\\n",
    "    .write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .mode(OVERWRITE_MODE) \\\n",
    "    .option(\"url\", \"jdbc:postgresql://host.docker.internal:5433/postgres\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"testPassword\") \\\n",
    "    .option(\"dbtable\", \"tarea3\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Clean flights data saved!\\n\")"
   ]
  },
  {
   "source": [
    "# Inspección de datos\n",
    "Previo a entrenar el modelo es común que se realice algún tipo de descripción de los datos, para tener una idea del tipo de problema con el que nos enfrentamos. A continuación, algunas observaciones interesantes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos. Esta vez desde la base de datos\n",
    "clear_flights_df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://host.docker.internal:5433/postgres\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"testPassword\") \\\n",
    "    .option(\"dbtable\", \"tarea3\") \\\n",
    "    .load()\n",
    "\n",
    "clear_flights_df.show()"
   ]
  },
  {
   "source": [
    "## Información Descriptiva de los Datos.\n",
    "Se muestran histogramas y resúmenes descriptivos de algunas de las variables disponibles."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información descriptiva de alguno valores interesantes del dataframe.\n",
    "clear_flights_df.describe([\n",
    "    'age', \n",
    "    'flight_distance', \n",
    "    'departure_delay_minutes',\n",
    "    'arrival_delay_minutes']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de histogramas.\n",
    "def print_hist(rdd_histogram_data):\n",
    "    heights = np.array(rdd_histogram_data[1])\n",
    "    full_bins = rdd_histogram_data[0]\n",
    "    mid_point_bins = full_bins[:-1]\n",
    "    widths = [abs(i - j) for i, j in zip(full_bins[:-1], full_bins[1:])]\n",
    "    plt.bar(mid_point_bins, heights, width=widths, color='b')\n",
    "    plt.show()\n",
    "\n",
    "# Obtener histograma, con los parámetros de rango determinados\n",
    "# y para la propiedad especificada.\n",
    "def create_histogram(h_start=0, h_stop=100, h_step=5, h_prop=\"age\"):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        h_start: Histogram start value.\n",
    "        h_stop: Histogram end value.\n",
    "        h_step: Iteration size.\n",
    "        h_prop: Name of property to create Histogram for.\n",
    "    \"\"\"\n",
    "    buckets = np.arange(\n",
    "        start=h_start, \n",
    "        stop=h_stop, \n",
    "        step=h_step).tolist()\n",
    "\n",
    "    rdd_histogram_data = clear_flights_df\\\n",
    "        .select(h_prop)\\\n",
    "        .rdd\\\n",
    "        .flatMap(lambda x: x)\\\n",
    "        .histogram(buckets)\n",
    "\n",
    "    print_hist(rdd_histogram_data)\n",
    "\n",
    "# Age Histogram.\n",
    "create_histogram(0,100,5,'age')\n",
    "\n",
    "# Flight_distance Histogram.\n",
    "create_histogram(50,6951,50,'flight_distance')\n",
    "\n",
    "# Departure Delay in Minutes Histogram.\n",
    "create_histogram(0,500,20,'departure_delay_minutes')\n",
    "\n",
    "# Arrival Delay in Minutes Histogram.\n",
    "create_histogram(0,500,20,'arrival_delay_minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para realizar operaciones más detalladas es necesario expresar las filas originales en vectores\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'age', \n",
    "        'flight_distance', \n",
    "        'seat_comfort',\n",
    "        'departure_arrival_time_convenient',\n",
    "        'food_drink',\n",
    "        'gate_location',\n",
    "        'inflight_wifi_service',\n",
    "        'inflight_entertainment',\n",
    "        'online_support',\n",
    "        'ease_of_online_booking',\n",
    "        'onboard_service',\n",
    "        'leg_room_service',\n",
    "        'baggage_handling',\n",
    "        'checkin_service',\n",
    "        'cleanliness',\n",
    "        'online_boarding',\n",
    "        'departure_delay_minutes',\n",
    "        'arrival_delay_minutes',\n",
    "        'isMale',\n",
    "        'isFemale',\n",
    "        'isLoyalCustomer',\n",
    "        'isDisloyalCustomer',\n",
    "        'isBusinessTravel',\n",
    "        'isPersonalTravel',\n",
    "        'isBusinessClass',\n",
    "        'isEcoClass',\n",
    "        'isOtherClass'],\n",
    "    outputCol='features')\n",
    "\n",
    "vector_df = assembler.transform(clear_flights_df)\n",
    "vector_df = vector_df.select(['features', 'isSatisfied'])\n",
    "vector_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con la representación de vectores podemos calcular correlaciones\n",
    "pearson_matrix = Correlation.corr(vector_df, 'features').collect()[0][0]\n",
    "\n",
    "sns.heatmap(pearson_matrix.toArray(), annot=True, fmt=\".2f\", cmap='viridis')"
   ]
  },
  {
   "source": [
    "# Estandarización\n",
    "Como recordamos de los módulos anteriores es deseable que los datos se encuentren estandarizados o normalizados, para evitar que la magnitud de ciertos atributos dominen el proceso de entrenamiento. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler(inputCol='features', outputCol='scaled')\n",
    "scale_model = standard_scaler.fit(vector_df)\n",
    "\n",
    "scaled_df = scale_model.transform(vector_df)\n",
    "scaled_df = scaled_df.withColumnRenamed(\"isSatisfied\", \"label\")\n",
    "scaled_df.show()"
   ]
  },
  {
   "source": [
    "# Clasificación Binaria (Usando K Fold Cross Validation)\n",
    "Para entrenar los modelos, utilizaremos los algoritmos de Regresión Lineal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = scaled_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "print(\"Training Data Count: \", trainingData.count())\n",
    "print(\"Test Data Count:\", testData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1.\n",
    "\n",
    "# Utilizamos regersión logística para predicción binaria.\n",
    "lr = LogisticRegression(maxIter=10)\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=lr, \n",
    "    estimatorParamMaps=grid, \n",
    "    evaluator=evaluator,\n",
    "    parallelism=3)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters.\n",
    "# Modelo 1 a utilizar.\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "trainingSummary = cvModel.bestModel.summary\n",
    "print(\"Modelo 1: Regresión Logística\\n\")\n",
    "print(\"Total Iterations: \", trainingSummary.totalIterations)\n",
    "print(\"Objective History: \", trainingSummary.objectiveHistory)\n",
    "\n",
    "numFolds = cvModel.getNumFolds()\n",
    "print(\"Number of folds: \", numFolds)\n",
    "\n",
    "avgMetricsTest = cvModel.avgMetrics[0]\n",
    "print(\"Average metrics Test (First position): \", avgMetricsTest)\n",
    "\n",
    "evaluation = evaluator.evaluate(cvModel.transform(testData))\n",
    "\n",
    "print('Evaluator for training data: ', evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 2.\n",
    "\n",
    "from pyspark.mllib import linalg as mllib_linalg\n",
    "from pyspark.ml import linalg as ml_linalg\n",
    "\n",
    "def as_old(v):\n",
    "    if isinstance(v, ml_linalg.SparseVector):\n",
    "        return mllib_linalg.SparseVector(v.size, v.indices, v.values)\n",
    "    if isinstance(v, ml_linalg.DenseVector):\n",
    "        return mllib_linalg.DenseVector(v.values)\n",
    "    raise ValueError(\"Unsupported type {0}\".format(type(v)))\n",
    "\n",
    "parsedData = trainingData.rdd.map(lambda row: LabeledPoint(row.label, as_old(row.features)))\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "# Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "model = DecisionTree.trainClassifier(\n",
    "    parsedData, \n",
    "    numClasses=2, \n",
    "    categoricalFeaturesInfo={},\n",
    "    impurity='gini', \n",
    "    maxDepth=5,\n",
    "    maxBins=32)\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.rdd.map(lambda x: x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "name": "BigData-Leccion5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}