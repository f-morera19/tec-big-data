"""
NAME
    __main__.py

DESCRIPTION   
    Program entry point for homework 2.

Student: Fabian Morera Gutierrez.
Course: Big Data.
Instituto Tecnologico de Costa Rica.
2021
"""

import argparse
from pyspark.sql import SparkSession
from src.read_input import *
from src.data_processing import *
from src.write_data import *

# Default variables.
SRC_FOLDER_PATH = 'resources/*.json'
DEFAULT_OUTPUT_RIDES_INCOME_PATH = 'output/total_ingresos.csv'
DEFAULT_OUTPUT_RIDES_AMOUNT_PATH = 'output/total_viajes.csv'

# Read all json files from default directory.
riders_df = readJsonFilesFromPath(path=SRC_FOLDER_PATH)

# Extract json properties into columns in main dataframe.
formatted_df = flatten_jsonColumn(riders_df, showdf=True)

# Postal Codes Metadata.
postal_codes_df = get_union_source_data(formatted_df)

# Get the total of travels for each postal code.
total_travels_df = get_total_amount_formated_df(postal_codes_df)

# Get the total of income generated by each postal code.
total_income_df = get_total_income_formated_df(postal_codes_df)

# Get various metrics for Diber data.
metrics_df = get_metrics(formatted_df)
metrics_df.show()

# Write to csv file.
write_csv_to_output(
    total_travels_df,
    DEFAULT_OUTPUT_RIDES_AMOUNT_PATH)

write_csv_to_output(
    total_income_df,
    DEFAULT_OUTPUT_RIDES_INCOME_PATH)

total_travels_df.show()
total_income_df.show()

# Test command: spark-submit __main__.py